{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxXY+0UzbFha3Ex/vY6qas"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Contexto**\n",
        "\n",
        "Nesse desafio, quero criar um sistema de busca em bulas de remédios dentro de um acervo. Para que eu consiga localizar quais remédios resolvem os sintomas do paciente, permitindo que o Gemini AI contribua também com informações de contra-indicações ou sugestão de outros remédios que não estejam no acervo.\n",
        "\n",
        "---\n",
        "\n",
        "*Instalação do SDK do Google*\n"
      ],
      "metadata": {
        "id": "JAw6MpFjGbaq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FCy7gUosF1qk"
      },
      "outputs": [],
      "source": [
        "# Install\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Importação do Numpy (ferramenta matemática), Pandas (sistema tabular), PyPDF (biblioteca capaz de extrair informações de documentos em PDF) e Google Gemini*"
      ],
      "metadata": {
        "id": "u5Rc0UM4HQqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "google_api_key = userdata.get('COLE A API KEY')\n",
        "genai.configure(api_key=google_api_key)"
      ],
      "metadata": {
        "id": "qEvV0DzzF_O9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Trazer a lista de modelos de embedding*"
      ],
      "metadata": {
        "id": "7fL3lLA9Hm8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'embedContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "id": "kLLrIwguGA1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Conteúdo dos documentos que serão buscados*\n",
        "\n",
        "*   *Bula do Nimesulida*\n",
        "*   *Bula do Novalgina*\n",
        "*   *Bula do Tylenol*\n",
        "\n",
        "*Gostaria de ter colocado mais bulas, mas tive problema com limitação de payload para leitura dos documentos e não soube resolver.*"
      ],
      "metadata": {
        "id": "Dgnkax25HxpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Listagem de documentos que serão buscados\n",
        "\n",
        "def ler_bula_nimesulida():\n",
        "    with open(\"bula_nimesulida.txt\", \"r\", encoding=\"utf-8\") as arquivo_nimesulida:\n",
        "        texto_nimesulida = arquivo_nimesulida.read()\n",
        "        return texto_nimesulida\n",
        "\n",
        "def ler_bula_novalgina():\n",
        "    with open(\"bula_novalgina.txt\", \"r\", encoding=\"utf-8\") as arquivo_novalgina:\n",
        "        texto_novalgina = arquivo_novalgina.read()\n",
        "        return texto_novalgina\n",
        "\n",
        "def ler_bula_tylenol():\n",
        "    with open(\"bula_tylenol.txt\", \"r\", encoding=\"utf-8\") as arquivo_tylenol:\n",
        "        texto_tylenol = arquivo_tylenol.read()\n",
        "        return texto_tylenol\n",
        "\n",
        "DOCUMENT1 = {\n",
        "    \"Título\": \"Nimesulida\",\n",
        "    \"Conteúdo\": ler_bula_nimesulida()\n",
        "}\n",
        "DOCUMENT2 = {\n",
        "    \"Título\": \"Novalgina\",\n",
        "    \"Conteúdo\": ler_bula_novalgina()\n",
        "}\n",
        "DOCUMENT3 = {\n",
        "    \"Título\": \"Tylenol\",\n",
        "    \"Conteúdo\": ler_bula_tylenol()\n",
        "}\n",
        "\n",
        "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
      ],
      "metadata": {
        "id": "SADpd7LsGFUf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Criar um Dataframe e definição dos nomes das colunas*"
      ],
      "metadata": {
        "id": "rX-MgCMgebkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(documents)\n",
        "df.columns = [\"Titulo\", \"Conteudo\"]\n",
        "df"
      ],
      "metadata": {
        "id": "VySw3omdGG_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Definição do modelo de embedding*"
      ],
      "metadata": {
        "id": "fo4JiI05ekUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'models/embedding-001'"
      ],
      "metadata": {
        "id": "4aPKl0dpGIkr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Criando embedding para os documentos, usando a API do Google*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XtRH7YdfenUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_fn(title, text):\n",
        "  return genai.embed_content(model=model,\n",
        "                                 content=text,\n",
        "                                 title=title,\n",
        "                                 task_type=\"retrieval_document\")[\"embedding\"]"
      ],
      "metadata": {
        "id": "VrPKr6UsGKXk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Gerando embeddings para cada linha do seu DataFrame*"
      ],
      "metadata": {
        "id": "MFxKaiV7e1p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Embeddings\"] = df.apply(lambda row: embed_fn(row[\"Titulo\"], row[\"Conteudo\"][:3000]), axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "Nb31Ua9DGMG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Realizando uma busca semântica nos documentos, usando embeddings de texto.*"
      ],
      "metadata": {
        "id": "EUncg0YWfJ3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_e_buscar_consulta(consulta, base, model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model,\n",
        "                                 content=consulta,\n",
        "                                 task_type=\"retrieval_query\")[\"embedding\"]\n",
        "\n",
        "  produtos_escalares = np.dot(np.stack(df[\"Embeddings\"]), embedding_da_consulta)\n",
        "\n",
        "  indice = np.argmax(produtos_escalares)\n",
        "  return df.iloc[indice][\"Conteudo\"]"
      ],
      "metadata": {
        "id": "wyPW0cehGNzv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Define a consulta desejada e imprime o resultado com um limite de 200 caracteres.*"
      ],
      "metadata": {
        "id": "u9Z0WnlafgHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consulta = \"CONSULTA A SER FEITA",
        "\n",
        "trecho = gerar_e_buscar_consulta(consulta, df, model)\n",
        "print(trecho[:200])"
      ],
      "metadata": {
        "id": "kgoSGZIiGQXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Configurações da IA generativa*"
      ],
      "metadata": {
        "id": "FRwsW5UmfwTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "rXMHJJhoGTNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Adaptação do texto, para que a leitura fique mais \"palatável\".*"
      ],
      "metadata": {
        "id": "CSZc6_6kf02D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"Reescreva esse texto de uma forma mais fácil de ler, sem adicionar informações que não façam parte do texto: {trecho}\"\n",
        "\n",
        "model_2 = genai.GenerativeModel(\"gemini-1.0-pro\",\n",
        "                                generation_config=generation_config)\n",
        "response = model_2.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "f5-jTsCSGU-T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
